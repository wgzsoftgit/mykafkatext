kafka如何保证消息不丢失，主要从生产者端来考虑，生产者可以通过设置acks=all保证消息发送可靠

kafka如何保证消息不重复消费，主要从消费端来考虑，消费端要考虑如何保证幂等性（重复获取不可避免）

消息重复解决方案:

消息可以使用唯一id标识

生产者（ack=all 代表至少成功发送一次)

消费者 （offset手动提交，业务逻辑成功处理后，提交offset）

落表（主键或者唯一索引的方式，避免重复数据）

业务逻辑处理（选择唯一主键存储到Redis或者mongdb中，先查询是否存在，若存在则不处理；若不存在，
先插入Redis或Mongdb,再进行业务逻辑处理）




底层根本原因：已经消费了数据，但是offset没提交。
原因1：强行kill线程，导致消费后的数据，offset没有提交。
原因2：设置offset为自动提交，关闭kafka时，如果在close之前，调用 consumer.unsubscribe()
则有可能部分offset没提交，下次重启会重复消费
————————————————
https://blog.csdn.net/qingqing7/java/article/details/80054281